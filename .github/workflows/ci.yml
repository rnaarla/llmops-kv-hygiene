# =============================================================================
# KV-Hygiene CI/CD Pipeline - Rebuilt from Scratch
# =============================================================================
# Clean, robust pipeline with fixed coverage collection and clear job flow
# =============================================================================

name: kv-hygiene-ci

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  COVERAGE_THRESHOLD: '90'
  PYTHON_VERSION: '3.11'
  TEST_SELECTION_ENABLED: 'true'
  TEST_SELECTION_THRESHOLD: '20'
  # AI configuration
  AI_CONFIDENCE_THRESHOLD: '0.9'
  AI_MODEL: 'gpt-4-turbo-preview'
  AI_MAX_TOKENS: '4096'

permissions:
  contents: write
  packages: write
  security-events: write
  id-token: write
  pull-requests: write

jobs:
  # ===========================================================================
  # PHASE 0: Dynamic Configuration
  # ===========================================================================
  generate-matrix:
    name: Generate Test Matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.mk.outputs.matrix }}
      changed_files: ${{ steps.changes.outputs.files }}
      test_selection_mode: ${{ steps.changes.outputs.mode }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for accurate diff analysis

      # === CONTEXT-AWARE TEST SELECTION ===
      - name: Detect changed files
        id: changes
        run: |
          python - <<'PY'
          import json, os, subprocess, sys

          # Get changed files compared to base branch
          base = os.environ.get('GITHUB_BASE_REF', 'main')
          if os.environ.get('GITHUB_EVENT_NAME') == 'pull_request':
              cmd = f'git diff --name-only origin/{base}...HEAD'
          else:
              cmd = 'git diff --name-only HEAD~1 HEAD'

          result = subprocess.run(cmd.split(), capture_output=True, text=True)
          changed = [f.strip() for f in result.stdout.split('\n') if f.strip()]

          print(f"Changed files: {changed}")

          # Determine test selection mode
          threshold = int(os.environ.get('TEST_SELECTION_THRESHOLD', '20'))
          enabled = os.environ.get('TEST_SELECTION_ENABLED', 'true').lower() == 'true'

          mode = 'full'
          if enabled and len(changed) < threshold:
              # Check if dependency-critical files changed
              critical_patterns = ['.github/', 'requirements.txt', 'setup.py', 'pyproject.toml']
              has_critical = any(any(p in f for p in critical_patterns) for f in changed)
              mode = 'full' if has_critical else 'selective'

          serialized = json.dumps(changed)
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              print(f"files={serialized}", file=f)
              print(f"mode={mode}", file=f)

          print(f"Test selection mode: {mode}")
          PY

      - name: Generate matrix from config
        id: mk
        run: |
          python3 - <<'PY'
          import json, os, sys
          try:
              path = 'ci_cd/test_matrix.json'
              with open(path, 'r', encoding='utf-8') as f:
                  cfg = json.load(f)
              matrix = {
                'os': cfg.get('platform', ['ubuntu-latest']),
                'python-version': cfg.get('python', ['3.11'])
              }
              print('Matrix:', matrix)
              with open(os.environ['GITHUB_OUTPUT'], 'a') as output:
                  output.write(f"matrix={json.dumps(matrix)}\n")
          except json.JSONDecodeError as e:
              print(f"ERROR: Invalid JSON in {path}: {e}", file=sys.stderr)
              sys.exit(1)
          except Exception as e:
              print(f"ERROR: Failed to load matrix: {e}", file=sys.stderr)
              sys.exit(1)
          PY

  # ===========================================================================
  # PHASE 1: Code Quality
  # ===========================================================================
  lint:
    name: Lint & Type Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Ruff
        run: ruff check .

      - name: Run Black
        run: black --check .

      - name: Run Mypy
        run: mypy tools tests

  policy-guard:
    name: Policy Validation
    needs: lint
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Install Conftest
        run: |
          set -euo pipefail
          VERSION="0.45.0"
          curl -sSL -o conftest.tar.gz "https://github.com/open-policy-agent/conftest/releases/download/v${VERSION}/conftest_${VERSION}_Linux_x86_64.tar.gz"
          tar -xzf conftest.tar.gz
          sudo mv conftest /usr/local/bin/conftest
          conftest --version

      - name: Evaluate policies
        run: conftest test .github/workflows/ci.yml -p policy

  # ===========================================================================
  # PHASE 2: Testing with Coverage
  # ===========================================================================
  test:
    name: Test (${{ matrix.os }}, Python ${{ matrix.python-version }})
    needs: [policy-guard, generate-matrix]
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run tests with coverage
        run: |
          mkdir -p coverage-reports
          pytest -v \
            --cov=tools \
            --cov-report=xml:coverage-reports/coverage.xml \
            --cov-report=json:coverage-reports/coverage.json \
            --cov-report=term

      - name: Verify coverage file exists
        run: |
          if [ ! -f coverage-reports/coverage.json ]; then
            echo "ERROR: coverage.json was not created!"
            exit 1
          fi
          echo "‚úÖ Coverage file created successfully"
          ls -lh coverage-reports/

      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-${{ matrix.os }}-py${{ matrix.python-version }}
          path: coverage-reports/coverage.json
          retention-days: 7

  # ===========================================================================
  # PHASE 3: Coverage Aggregation & Quality Gate
  # ===========================================================================
  coverage:
    name: Aggregate Coverage & Quality Gate
    needs: test
    runs-on: ubuntu-latest
    outputs:
      coverage_pct: ${{ steps.aggregate.outputs.coverage }}

    steps:
      - uses: actions/checkout@v4

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-coverage
          pattern: coverage-*
          merge-multiple: false

      - name: Debug - Show downloaded artifacts
        run: |
          echo "=== Downloaded artifacts structure ==="
          find all-coverage -type f -name "*.json" | sort
          echo ""
          echo "=== Artifact sizes ==="
          find all-coverage -type f -name "*.json" -exec ls -lh {} \;

      - name: Aggregate coverage
        id: aggregate
        run: |
          python3 << 'EOF'
          import json
          import sys
          import os
          from pathlib import Path

          coverage_dir = Path("all-coverage")
          coverage_files = list(coverage_dir.rglob("coverage.json"))

          print(f"Found {len(coverage_files)} coverage files")

          if not coverage_files:
              print("ERROR: No coverage files found!")
              print("Directory structure:")
              for item in coverage_dir.rglob("*"):
                  print(f"  {item}")
              sys.exit(1)

          total_statements = 0
          total_covered = 0

          for file in coverage_files:
              print(f"\nProcessing: {file}")
              try:
                  data = json.loads(file.read_text())
                  totals = data.get("totals", {})
                  statements = totals.get("num_statements", 0)
                  covered = totals.get("covered_lines", 0)

                  print(f"  Statements: {statements}")
                  print(f"  Covered: {covered}")
                  print(f"  Coverage: {(covered/statements*100):.2f}%" if statements > 0 else "  Coverage: 0%")

                  total_statements += statements
                  total_covered += covered
              except Exception as e:
                  print(f"  ERROR reading file: {e}")
                  continue

          if total_statements == 0:
              print("\nERROR: No statements found in any coverage file!")
              sys.exit(1)

          coverage_pct = (total_covered / total_statements) * 100

          print(f"\n{'='*60}")
          print(f"TOTAL COVERAGE: {coverage_pct:.2f}%")
          print(f"Total Statements: {total_statements}")
          print(f"Total Covered: {total_covered}")
          print(f"{'='*60}")

          # Write to GitHub output
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"coverage={coverage_pct:.2f}\n")

          # Save aggregate report
          aggregate_data = {
              "coverage_pct": coverage_pct,
              "total_statements": total_statements,
              "total_covered": total_covered,
              "file_count": len(coverage_files)
          }

          Path("aggregate-coverage.json").write_text(json.dumps(aggregate_data, indent=2))

          print(f"\n‚úÖ Aggregate coverage: {coverage_pct:.2f}%")
          EOF

      - name: Quality gate - Coverage threshold
        run: |
          COVERAGE="${{ steps.aggregate.outputs.coverage }}"
          THRESHOLD="${{ env.COVERAGE_THRESHOLD }}"

          echo "Coverage: ${COVERAGE}%"
          echo "Threshold: ${THRESHOLD}%"

          if (( $(echo "$COVERAGE < $THRESHOLD" | bc -l) )); then
            echo "‚ùå Coverage ${COVERAGE}% is below threshold ${THRESHOLD}%"
            exit 1
          else
            echo "‚úÖ Coverage ${COVERAGE}% meets threshold ${THRESHOLD}%"
          fi

      - name: Upload aggregate coverage
        uses: actions/upload-artifact@v4
        with:
          name: aggregate-coverage
          path: aggregate-coverage.json

  # ===========================================================================
  # PHASE 3.5: Meta Testing & Chaos Validation
  # ===========================================================================
  meta-self-test:
    name: Meta Self Test
    needs: coverage
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Download aggregate coverage
        uses: actions/download-artifact@v4
        with:
          name: aggregate-coverage
          path: meta_self_test
        continue-on-error: true

      - name: Download raw coverage artifacts
        uses: actions/download-artifact@v4
        with:
          path: meta_self_test/raw
          pattern: coverage-*
          merge-multiple: true
        continue-on-error: true

      - name: Validate coverage reproducibility
        run: |
          python tools/meta_self_test.py \
            --aggregate meta_self_test/aggregate-coverage.json \
            --artifacts meta_self_test/raw

  chaos-validation:
    name: Chaos Validation
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install runtime dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run chaos simulation
        run: |
          export PYTHONPATH="$PYTHONPATH:$(pwd)"
          python tools/chaos_validation.py

  # ===========================================================================
  # PHASE 3.7: AI-Assisted Triage
  # ===========================================================================
  ai-triage:
    name: AI-Assisted Error Triage
    needs: [lint, test, coverage, meta-self-test, chaos-validation]
    runs-on: ubuntu-latest
    if: always()
    timeout-minutes: 10
    outputs:
      fix_confidence: ${{ steps.triage.outputs.confidence }}
      has_flaky_tests: ${{ steps.triage.outputs.flaky }}
      triage_summary: ${{ steps.triage.outputs.summary }}
    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
        continue-on-error: true

      - name: Collect errors and create report
        id: collect
        run: |
          mkdir -p ai_analysis
          python - <<'PY'
          import json, pathlib, xml.etree.ElementTree as ET

          errors = []
          warnings = []

          # Parse test results from XML
          for xml_file in pathlib.Path('artifacts').rglob('*.xml'):
              try:
                  tree = ET.parse(xml_file)
                  for testcase in tree.findall('.//testcase'):
                      failure = testcase.find('failure')
                      if failure is not None:
                          errors.append({
                              'type': 'test_failure',
                              'test': testcase.get('name'),
                              'file': testcase.get('file'),
                              'message': failure.get('message', ''),
                              'details': (failure.text or '')[:500]
                          })
              except: pass

          # Parse coverage for low-coverage warnings
          for json_file in pathlib.Path('artifacts').rglob('coverage.json'):
              try:
                  data = json.loads(json_file.read_text())
                  for file, info in data.get('files', {}).items():
                      cov = info.get('summary', {}).get('percent_covered', 100)
                      if cov < 80:
                          warnings.append({
                              'type': 'low_coverage',
                              'file': file,
                              'coverage': cov
                          })
              except: pass

          report = {
              'errors': errors[:10],
              'warnings': warnings[:10],
              'error_count': len(errors),
              'warning_count': len(warnings)
          }

          pathlib.Path('ai_analysis/error_report.json').write_text(json.dumps(report, indent=2))
          print(f"üìä Collected {len(errors)} errors, {len(warnings)} warnings")
          PY

      - name: AI-powered triage
        id: triage
        env:
          OPENAI_API_KEY: ${{ secrets.AI_API_KEY }}
        run: |
          python - <<'PY'
          import json, os, pathlib, sys, urllib.request

          report_path = pathlib.Path('ai_analysis/error_report.json')
          report = json.loads(report_path.read_text())

          if report['error_count'] == 0:
              print("‚úÖ No errors to triage")
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write("confidence=0.0\n")
                  f.write("flaky=false\n")
                  f.write("summary=No errors detected\n")
              sys.exit(0)

          api_key = os.environ.get('OPENAI_API_KEY')
          if not api_key:
              print("‚ö†Ô∏è AI_API_KEY not set, skipping")
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write("confidence=0.0\n")
                  f.write("flaky=false\n")
                  f.write("summary=AI key not configured\n")
              sys.exit(0)

          # Prepare prompt
          errors_text = json.dumps(report['errors'], indent=2)
          prompt = f"""Analyze these CI/CD failures and provide:
          1. Root cause clusters (group similar errors)
          2. Flaky test detection
          3. Fix recommendations with confidence (0-1)
          4. Priority ranking

          Errors: {errors_text}

          Respond in JSON:
          {{
            "clusters": [{{"type": "...", "count": N, "root_cause": "..."}}],
            "flaky_tests": ["test1"],
            "fixes": [{{"confidence": 0.95, "description": "..."}}],
            "summary": "Brief summary"
          }}"""

          try:
              request_data = {
                  "model": os.environ.get('AI_MODEL', 'gpt-4-turbo-preview'),
                  "messages": [{"role": "user", "content": prompt}],
                  "max_tokens": int(os.environ.get('AI_MAX_TOKENS', '4096')),
                  "temperature": 0.3
              }

              req = urllib.request.Request(
                  'https://api.openai.com/v1/chat/completions',
                  data=json.dumps(request_data).encode(),
                  headers={
                      'Content-Type': 'application/json',
                      'Authorization': f'Bearer {api_key}'
                  }
              )

              with urllib.request.urlopen(req, timeout=30) as response:
                  result = json.loads(response.read().decode())
                  ai_response = result['choices'][0]['message']['content']

                  # Extract JSON
                  start = ai_response.find('{')
                  end = ai_response.rfind('}') + 1
                  if start >= 0 and end > start:
                      triage_data = json.loads(ai_response[start:end])
                  else:
                      triage_data = {"summary": "Parse failed", "fixes": [], "flaky_tests": []}

                  pathlib.Path('ai_analysis/triage_report.json').write_text(json.dumps(triage_data, indent=2))

                  max_conf = max([f.get('confidence', 0) for f in triage_data.get('fixes', [])], default=0.0)
                  has_flaky = len(triage_data.get('flaky_tests', [])) > 0

                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                      f.write(f"confidence={max_conf}\n")
                      f.write(f"flaky={'true' if has_flaky else 'false'}\n")
                      f.write(f"summary={triage_data.get('summary', 'Done')}\n")

                  print(f"‚úÖ AI triage: confidence={max_conf}, flaky={has_flaky}")

          except Exception as e:
              print(f"‚ö†Ô∏è AI call failed: {e}")
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write("confidence=0.0\n")
                  f.write("flaky=false\n")
                  f.write(f"summary=API failed: {str(e)[:100]}\n")
          PY

      - name: Upload triage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-triage-report
          path: ai_analysis/

  # ===========================================================================
  # PHASE 4: Security Scanning
  # ===========================================================================
  security-scan:
    name: Security Scan (Trivy)
    needs: lint
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy filesystem scan
        uses: aquasecurity/trivy-action@0.33.0
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # ===========================================================================
  # PHASE 5: Docker Build & Scan (Main Branch Only)
  # ===========================================================================
  docker:
    name: Docker Build & Scan
    needs: [coverage, security-scan]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.cpu
          push: true
          tags: |
            ghcr.io/${{ github.repository }}:latest
            ghcr.io/${{ github.repository }}:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Scan Docker image with Trivy
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ghcr.io/${{ github.repository }}:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-image.sarif'

      - name: Upload image scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-image.sarif'

  docker-scan-pr:
    name: Scan Docker Images for PRs
    needs: [coverage, meta-self-test]
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    permissions:
      contents: read
      security-events: write
    steps:
      - uses: actions/checkout@v4

      - name: Pre-build disk cleanup
        run: |
          echo "Initial disk usage:"; df -h || true
          sudo rm -rf /usr/local/lib/android || true
          sudo rm -rf /usr/share/dotnet || true
          sudo rm -rf /opt/ghc || true
          sudo rm -rf /usr/local/share/boost || true
          docker system prune -af || true
          docker builder prune -af || true
          sudo apt-get clean || true
          echo "Disk usage after cleanup:"; df -h || true

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build CPU image (no push)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.cpu
          platforms: linux/amd64
          push: false
          tags: ghcr.io/${{ github.repository }}:pr-${{ github.event.pull_request.number }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Trivy scan CPU image
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ghcr.io/${{ github.repository }}:pr-${{ github.event.pull_request.number }}
          format: sarif
          output: trivy-pr-cpu.sarif
          severity: CRITICAL,HIGH
          ignore-unfixed: true
        continue-on-error: true

      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: trivy-pr-cpu.sarif

  # ===========================================================================
  # PHASE 6: Update Metrics
  # ===========================================================================
  update-metrics:
    name: Update Quality Metrics
    needs: [coverage, security-scan]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Download aggregate coverage
        uses: actions/download-artifact@v4
        with:
          name: aggregate-coverage

      - name: Update quality metrics
        run: |
          python3 << 'EOF'
          import json
          from pathlib import Path
          from datetime import datetime

          # Load aggregate coverage
          aggregate = json.loads(Path("aggregate-coverage.json").read_text())
          coverage_pct = aggregate["coverage_pct"]

          # Load or create metrics file
          metrics_file = Path("ci_metrics/quality_metrics.json")
          metrics_file.parent.mkdir(exist_ok=True)

          if metrics_file.exists():
              metrics = json.loads(metrics_file.read_text())
          else:
              metrics = {
                  "coverage": {"baseline": 90.0, "current": 0.0},
                  "vulnerabilities": {"high": 0, "critical": 0},
                  "sbom": {"baseline_hash": "", "current_hash": ""},
                  "history": []
              }

          # Update current coverage
          metrics["coverage"]["current"] = coverage_pct

          # Update baseline (moving average of last 5 successful runs)
          metrics["history"].append({
              "timestamp": datetime.utcnow().isoformat(),
              "coverage": coverage_pct,
              "run_id": "${{ github.run_id }}"
          })

          # Keep only last 10 history entries
          metrics["history"] = metrics["history"][-10:]

          # Calculate new baseline from successful runs
          successful_runs = [h for h in metrics["history"] if h["coverage"] > 0]
          if len(successful_runs) >= 3:
              recent_coverages = [h["coverage"] for h in successful_runs[-5:]]
              metrics["coverage"]["baseline"] = sum(recent_coverages) / len(recent_coverages)

          metrics["last_updated"] = datetime.utcnow().isoformat()

          # Write back
          metrics_file.write_text(json.dumps(metrics, indent=2))

          print(f"‚úÖ Updated metrics:")
          print(f"   Current coverage: {coverage_pct:.2f}%")
          print(f"   Baseline coverage: {metrics['coverage']['baseline']:.2f}%")
          EOF

      - name: Commit updated metrics
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add ci_metrics/quality_metrics.json
          git diff --staged --quiet || git commit -m "ci: update quality metrics [skip ci]"
          git push

  # ===========================================================================
  # PHASE 6.5: Canary Validation
  # ===========================================================================
  canary-validation:
    name: Canary Validation
    needs: [docker, update-metrics]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
    steps:
      - uses: actions/checkout@v4

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull canary image
        run: |
          docker pull ghcr.io/${{ github.repository }}:${{ github.sha }}

      - name: Run container smoke check
        run: |
          docker run --rm ghcr.io/${{ github.repository }}:${{ github.sha }} \
            python -c "import json; print(json.dumps({'status':'ok'}))"

      - name: Evaluate telemetry
        run: |
          python tools/canary_validate.py \
            --metrics ci_metrics/quality_metrics.json \
            --min-coverage 90.0

  # ===========================================================================
  # PHASE 7: Summary Report
  # ===========================================================================
  summary:
    name: CI Summary
    needs: [lint, test, coverage, security-scan]
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: Generate summary
        run: |
          echo "## üéØ CI Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Lint | ${{ needs.lint.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Tests | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Coverage | ${{ needs.coverage.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Scan | ${{ needs.security-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.coverage.outputs.coverage_pct }}" != "" ]; then
            echo "### üìä Coverage: ${{ needs.coverage.outputs.coverage_pct }}%" >> $GITHUB_STEP_SUMMARY
          fi
