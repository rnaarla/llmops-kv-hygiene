name: kv-hygiene-ci

env:
  # Optional gating controls. Set VULN_GATING=1 (e.g. repository / org env var or secret) to activate.
  VULN_GATING: ''
  # Soft thresholds (counts) for HIGH / CRITICAL; defaults effectively disable unless overridden.
  MAX_HIGH: '9999'
  MAX_CRITICAL: '9999'

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 6 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  packages: write
  security-events: write

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.mk.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
      - id: mk
        run: |
          python - <<'PY'
          import json, os
          path = 'ci_cd/test_matrix.json'
          with open(path,'r',encoding='utf-8') as f:
              cfg = json.load(f)
          matrix = {
            'os': cfg.get('platform', ['ubuntu-latest']),
            'python-version': cfg.get('python', ['3.11'])
          }
          print('Matrix:', matrix)
          print(f"matrix={json.dumps(matrix)}", file=open(os.environ['GITHUB_OUTPUT'],'a'))
          PY

  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - name: Install dev dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Type ignore policy audit
        run: python tools/audit_type_ignores.py
      - name: Ruff
        run: ruff check . --output-format=github
      - name: Black check
        run: black --check .
      - name: Mypy (tools+tests via config) with cache
        env:
          MYPY_CACHE_DIR: .mypy_cache
        run: mypy --config-file mypy.ini tools tests
      - name: Upload mypy cache
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mypy-cache
          path: .mypy_cache
      - name: Tool versions summary
        if: always()
        run: |
          echo "Python $(python -V)" || true
          ruff --version || true
          black --version || true
          mypy --version || true

  test:
    needs: [lint, generate-matrix]
    strategy:
      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run tests with coverage
        run: |
          mkdir -p reports
          pytest --maxfail=1 --disable-warnings -q \
            --cov=tools --cov-report=term-missing \
            --cov-report=xml:reports/coverage.xml \
            --cov-report=json:reports/coverage.json \
            --cov-fail-under=90
      - uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.os }}-${{ matrix.python-version }}
          path: reports/coverage.xml
      - uses: actions/upload-artifact@v4
        with:
          name: coverage-raw-${{ matrix.os }}-${{ matrix.python-version }}
          path: reports/coverage.json
      - name: Generate metrics JSON and verify HMAC chain
        env:
          FORENSIC_HMAC_SECRET: ci-secret
        run: |
          python - <<'PY'
          import json
          from tools.cache_tracer import CacheTracer, ForensicLogger
          t = CacheTracer()
          h = t.allocate(tenant_id="ci", request_id="ci-1", model_id="m", shape=(128,), dtype="float32", device="cpu", framework="numpy")
          t.mark_in_use(h)
          cov = t.sanitize(h, async_=False, verify=True)
          try: t.free(h)
          except Exception: pass
          t.export_metrics("forensics/coverage.json")
          res = ForensicLogger.verify_chain("forensics/kv_cache.log")
          print("Coverage:", cov)
          print("Metrics:", open("forensics/coverage.json").read())
          print("Forensic chain:", json.dumps(res))
          PY
      - name: Verify rotated forensic chain (all files)
        run: |
          python - <<'PY'
          import sys, json
          from tools.cache_tracer import ForensicLogger
          res = ForensicLogger.verify_all('forensics/kv_cache.log')
          print(json.dumps(res))
          sys.exit(0 if res.get('ok') else 2)
          PY
      - name: Run eviction checker
        run: |
          python tools/eviction_checker.py forensics/coverage.json \
            --coverage-min 99.9 --unsanitized-max 0 --quarantine-max 0 \
            --out forensics/verdict.json
          cat forensics/verdict.json
      - uses: actions/upload-artifact@v4
        with:
          name: reports-and-forensics-${{ matrix.os }}-${{ matrix.python-version }}
          path: |
            reports/**
            forensics/**

  coverage-aggregate:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/download-artifact@v4
        with:
          path: coverage_artifacts
          pattern: coverage-*
          merge-multiple: true
      - name: Combine coverage
        run: |
          python - <<'PY'
          import json, pathlib, sys
          files = list(pathlib.Path('coverage_artifacts').rglob('coverage.json'))
          total_covered=0; total_statements=0
          for fp in files:
              data=json.loads(fp.read_text())
              totals = data.get('totals') or {}
              total_covered += totals.get('covered_lines',0)
              total_statements += totals.get('num_statements',0)
          pct = (total_covered/total_statements*100) if total_statements else 0.0
          print(f'Aggregated coverage: {pct:.2f}%')
          sys.exit(0 if pct >= 90.0 else 2)
          PY

  trivy-repo-scan:
    name: Repo vulnerability + secret scan (fs)
    needs: coverage-aggregate
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'
    steps:
      - uses: actions/checkout@v4
      - name: Trivy filesystem scan JSON (vuln + secrets)
        uses: aquasecurity/trivy-action@0.33.0
        with:
          scan-type: fs
          scanners: vuln,secret
          format: json
          severity: CRITICAL,HIGH
          ignore-unfixed: true
          exit-code: '0'
          output: trivy-fs.json
      - name: Trivy filesystem scan SARIF (vuln + secrets)
        uses: aquasecurity/trivy-action@0.33.0
        with:
          scan-type: fs
          scanners: vuln,secret
          format: sarif
          severity: CRITICAL,HIGH
          ignore-unfixed: true
          exit-code: '0'
          output: trivy-fs.sarif
      - name: Upload Trivy FS SARIF
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-fs.sarif
          category: trivy-fs
        continue-on-error: true
      - name: Upload repo scan reports
        uses: actions/upload-artifact@v4
        with:
          name: trivy-fs-report
          path: |
            trivy-fs.json
            trivy-fs.sarif
      - name: FS vulnerability threshold gate
        if: env.VULN_GATING == '1'
        run: |
          python - <<'PY'
          import json, os, sys
          data = json.load(open('trivy-fs.json'))
          high=critical=0
          for result in data.get('Results', []) or []:
              for v in result.get('Vulnerabilities', []) or []:
                  sev = (v.get('Severity') or '').upper()
                  if sev == 'HIGH': high += 1
                  elif sev == 'CRITICAL': critical += 1
              for s in result.get('Secrets', []) or []:  # secrets are informational for now
                  pass
          max_high = int(os.environ.get('MAX_HIGH','9999'))
          max_critical = int(os.environ.get('MAX_CRITICAL','9999'))
          print(f'FS scan counts: HIGH={high} CRITICAL={critical} (limits H={max_high} C={max_critical})')

          if critical > max_critical or high > max_high:
              print('Threshold exceeded (filesystem scan). Failing job.')
              sys.exit(2)
          PY

  docker-images:
    name: Build and push Docker images (CPU + CUDA)
    needs: coverage-aggregate
    if: github.event_name != 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      - id: prep
        run: |
          echo "repo=ghcr.io/${GITHUB_REPOSITORY,,}" >> $GITHUB_OUTPUT
          echo "sha=${GITHUB_SHA::12}" >> $GITHUB_OUTPUT
      - name: Build and push CPU image
        id: build_cpu
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.cpu
          platforms: linux/amd64
          push: true
          cache-from: type=gha
          cache-to: type=gha,mode=max
          tags: |
            ${{ steps.prep.outputs.repo }}:cpu-latest
            ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
      - name: Build and push CUDA image
        id: build_cuda
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.cuda
          platforms: linux/amd64
          push: true
          tags: |
            ${{ steps.prep.outputs.repo }}:cuda-latest
            ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          build-args: |
            TORCH_INDEX_URL=https://download.pytorch.org/whl/cu121
          cache-from: type=gha
          cache-to: type=gha,mode=max
      - name: Trivy scan (CPU)
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          format: sarif
          output: trivy-cpu.sarif
          severity: CRITICAL,HIGH
          vuln-type: os,library
          ignore-unfixed: true
          exit-code: '0'
        continue-on-error: true
      - name: Trivy scan (CUDA)
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          format: sarif
          output: trivy-cuda.sarif
          severity: CRITICAL,HIGH
          vuln-type: os,library
          ignore-unfixed: true
          exit-code: '0'
        continue-on-error: true
      - name: Trivy scan JSON (CPU)
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          format: json
          output: trivy-cpu.json
          severity: CRITICAL,HIGH
          vuln-type: os,library
          ignore-unfixed: true
          exit-code: '0'
        continue-on-error: true
      - name: Trivy scan JSON (CUDA)
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          format: json
          output: trivy-cuda.json
          severity: CRITICAL,HIGH
          vuln-type: os,library
          ignore-unfixed: true
          exit-code: '0'
        continue-on-error: true
      - name: Upload Trivy results (CPU)
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-cpu.sarif
          category: trivy-image-cpu
        continue-on-error: true
      - name: Upload Trivy results (CUDA)
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-cuda.sarif
          category: trivy-image-cuda
        continue-on-error: true
      - name: Normalize vulnerabilities (Trivy + Grype placeholder pre-SBOM)
        run: |
          python - <<'PY'
          import json, glob, os
          agg = {}
          def add(sev):
              sev=sev.upper()
              if sev not in agg: agg[sev]=0
              agg[sev]+=1
          # Trivy JSON (if present yet; SBOM not required)
          for f in ['trivy-cpu.json','trivy-cuda.json']:
              if not os.path.exists(f):
                  continue
              data=json.load(open(f))
              for res in data.get('Results',[]) or []:
                  for v in res.get('Vulnerabilities',[]) or []:
                      sev=v.get('Severity')
                      if sev: add(sev)
          # Grype will be processed later after SBOM; second normalization step will overwrite
          json.dump({'counts':agg,'stage':'pre-sbom'}, open('vuln-summary-incremental.json','w'), indent=2)
          print('Pre-SBOM vuln counts:', agg)
          PY
      - name: Free disk space (pre-SBOM)
        run: |
          echo "Disk usage before cleanup:" || true
          df -h || true
          docker system prune -af || true
          docker builder prune -af || true
          sudo rm -rf /var/lib/docker/tmp/* || true
          sudo rm -rf /tmp/* || true
          echo "Disk usage after cleanup:" || true
          df -h || true
      - name: Generate SBOM (Syft CPU)
        uses: anchore/sbom-action@v0.17.2
        with:
          image: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          output-file: sbom-cpu-${{ steps.prep.outputs.sha }}.spdx.json
          format: spdx-json
      - name: Generate SBOM (Syft CUDA)
        uses: anchore/sbom-action@v0.17.2
        with:
          image: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          output-file: sbom-cuda-${{ steps.prep.outputs.sha }}.spdx.json
          format: spdx-json
      - name: Generate SBOM (Syft CPU, CycloneDX)
        uses: anchore/sbom-action@v0.17.2
        with:
          image: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          output-file: sbom-cpu-${{ steps.prep.outputs.sha }}.cyclonedx.json
          format: cyclonedx-json
      - name: Generate SBOM (Syft CUDA, CycloneDX)
        uses: anchore/sbom-action@v0.17.2
        with:
          image: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          output-file: sbom-cuda-${{ steps.prep.outputs.sha }}.cyclonedx.json
          format: cyclonedx-json
      - name: Cross-validate SBOM with Grype (CPU)
        run: |
          docker run --rm -v $PWD:/scan anchore/grype:v0.80.0 \
            sbom:/scan/sbom-cpu-${{ steps.prep.outputs.sha }}.spdx.json \
            --fail-on high --output json > grype-cpu.json
          cat grype-cpu.json
        continue-on-error: true
      - name: Cross-validate SBOM with Grype (CUDA)
        run: |
          docker run --rm -v $PWD:/scan anchore/grype:v0.80.0 \
            sbom:/scan/sbom-cuda-${{ steps.prep.outputs.sha }}.spdx.json \
            --fail-on high --output json > grype-cuda.json
          cat grype-cuda.json
        continue-on-error: true
      - name: Normalize vulnerabilities (Trivy + Grype final)
        run: |
          python - <<'PY'
          import json, os, glob
          counts = {}
          def add(sev):
              sev=sev.upper(); counts[sev]=counts.get(sev,0)+1
          # Trivy image scans
          for f in ['trivy-cpu.json','trivy-cuda.json']:
              if os.path.exists(f):
                  data=json.load(open(f))
                  for res in data.get('Results',[]) or []:
                      for v in res.get('Vulnerabilities',[]) or []:
                          if v.get('Severity'): add(v['Severity'])
          # Grype scans
          for f in ['grype-cpu.json','grype-cuda.json']:
              if os.path.exists(f):
                  data=json.load(open(f))
                  for m in data.get('matches',[]) or []:
                      sev = (((m.get('vulnerability') or {}).get('severity')) or '').upper()
                      if sev: add(sev)
          # FS scan if artifact present (same job not, but may be copied in future)
          if os.path.exists('trivy-fs.json'):
              data=json.load(open('trivy-fs.json'))
              for res in data.get('Results',[]) or []:
                  for v in res.get('Vulnerabilities',[]) or []:
                      if v.get('Severity'): add(v['Severity'])
          json.dump({'counts':counts,'stage':'post-sbom'}, open('vuln-summary.json','w'), indent=2)
          print('Final aggregated vulnerability counts:', counts)
          PY
      - name: Vulnerability threshold gate (images)
        if: env.VULN_GATING == '1'
        run: |
          python - <<'PY'
          import json, os, sys
          data=json.load(open('vuln-summary.json'))
          counts=data.get('counts',{})
          high=counts.get('HIGH',0)

          critical=counts.get('CRITICAL',0)
          max_high=int(os.environ.get('MAX_HIGH','9999'))
          max_critical=int(os.environ.get('MAX_CRITICAL','9999'))
          print(f'Aggregated vuln counts: HIGH={high} CRITICAL={critical} (limits H={max_high} C={max_critical})')
          if critical > max_critical or high > max_high:
              print('Threshold exceeded (image scans). Failing job.')
              sys.exit(2)
          PY
      - name: Install Cosign
        uses: sigstore/cosign-installer@v3.4.0
      - name: Sign images (keyless)
        env:
          COSIGN_EXPERIMENTAL: 'true'
        run: |
          set -e
          for tag in \
            ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }} \
            ${{ steps.prep.outputs.repo }}:cpu-latest \
            ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }} \
            ${{ steps.prep.outputs.repo }}:cuda-latest; do
            echo "Signing $tag";
            cosign sign --yes $tag || exit 1;
          done
      - name: Attest build provenance (CPU)
        uses: actions/attest-build-provenance@v1
        with:
          subject-name: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          subject-digest: ${{ steps.build_cpu.outputs.digest }}
      - name: Attest build provenance (CUDA)
        uses: actions/attest-build-provenance@v1
        with:
          subject-name: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          subject-digest: ${{ steps.build_cuda.outputs.digest }}
      - name: Upload SBOM artifacts
        uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: |
            sbom-*.spdx.json
            sbom-*.cyclonedx.json
            grype-*.json
            vuln-summary*.json
            trivy-*.json

  docker-scan-pr:
    name: Scan Docker images for PRs (no push)
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - id: prep
        run: |
          REPO_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
          echo "repo=ghcr.io/${REPO_LOWER}" >> $GITHUB_OUTPUT
          echo "sha=${GITHUB_SHA::12}" >> $GITHUB_OUTPUT
      - name: Build CPU image (no push)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.cpu
          platforms: linux/amd64
          push: false
          tags: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      - name: Build CUDA image (no push)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.cuda
          platforms: linux/amd64
          push: false
          tags: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          build-args: |
            TORCH_INDEX_URL=https://download.pytorch.org/whl/cu121
          cache-from: type=gha
          cache-to: type=gha,mode=max
      - name: Trivy scan (CPU) [PR]
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          format: sarif
          output: trivy-cpu-pr.sarif
          severity: CRITICAL,HIGH
          vuln-type: os,library
          ignore-unfixed: true
          exit-code: '0'
        continue-on-error: true
      - name: Trivy scan (CUDA) [PR]
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          format: sarif
          output: trivy-cuda-pr.sarif
          severity: CRITICAL,HIGH
          vuln-type: os,library
          ignore-unfixed: true
          exit-code: '0'
        continue-on-error: true
      - name: Trivy scan JSON (CPU) [PR]
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          format: json
          output: trivy-cpu-pr.json
          severity: CRITICAL,HIGH
          vuln-type: os,library
          ignore-unfixed: true
          exit-code: '0'
        continue-on-error: true
      - name: Trivy scan JSON (CUDA) [PR]
        uses: aquasecurity/trivy-action@0.33.0
        with:
          image-ref: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          format: json
          output: trivy-cuda-pr.json
          severity: CRITICAL,HIGH
          vuln-type: os,library
          ignore-unfixed: true
          exit-code: '0'
        continue-on-error: true
      - name: Upload Trivy SARIF results (PR CPU)
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-cpu-pr.sarif
          category: trivy-pr-cpu
        continue-on-error: true
      - name: Upload Trivy SARIF results (PR CUDA)
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-cuda-pr.sarif
          category: trivy-pr-cuda
        continue-on-error: true
      - name: Normalize vulnerabilities (PR)
        run: |
          python - <<'PY'
          import json, os
          counts={}
          def add(sev):
              sev=sev.upper(); counts[sev]=counts.get(sev,0)+1
          for f in ['trivy-cpu-pr.json','trivy-cuda-pr.json']:
              if os.path.exists(f):
                  data=json.load(open(f))
                  for res in data.get('Results',[]) or []:
                      for v in res.get('Vulnerabilities',[]) or []:
                          if v.get('Severity'): add(v['Severity'])
          json.dump({'counts':counts,'stage':'pr'}, open('vuln-summary-pr.json','w'), indent=2)
          print('PR aggregated vulnerability counts:', counts)
          PY
      - name: Vulnerability threshold gate (PR images)
        if: env.VULN_GATING == '1'
        run: |
          python - <<'PY'
          import json, os, sys
          data=json.load(open('vuln-summary-pr.json'))
          counts=data.get('counts',{})
          high=counts.get('HIGH',0); critical=counts.get('CRITICAL',0)
          max_high=int(os.environ.get('MAX_HIGH','9999'))
          max_critical=int(os.environ.get('MAX_CRITICAL','9999'))
          print(f'PR vuln counts: HIGH={high} CRITICAL={critical} (limits H={max_high} C={max_critical})')
          if critical > max_critical or high > max_high:
              print('Threshold exceeded (PR image scans). Failing job.')
              sys.exit(2)
          PY
      - name: Generate SBOM (Syft CPU PR)
        uses: anchore/sbom-action@v0.17.2
        with:
          image: ${{ steps.prep.outputs.repo }}:cpu-${{ steps.prep.outputs.sha }}
          output-file: sbom-cpu-pr-${{ steps.prep.outputs.sha }}.spdx.json
          format: spdx-json
      - name: Generate SBOM (Syft CUDA PR)
        uses: anchore/sbom-action@v0.17.2
        with:
          image: ${{ steps.prep.outputs.repo }}:cuda-${{ steps.prep.outputs.sha }}
          output-file: sbom-cuda-pr-${{ steps.prep.outputs.sha }}.spdx.json
          format: spdx-json
      - name: Upload SBOM artifacts (PR)
        uses: actions/upload-artifact@v4
        with:
          name: sbom-pr
          path: |
            sbom-*-pr-*.spdx.json
            trivy-*-pr.json
            vuln-summary-pr.json
